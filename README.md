## Index
![dark](https://user-images.githubusercontent.com/12748752/132402918-976c6cc7-cc94-4267-9513-b3937504eb63.png)
### [_Linear Algebra_](https://github.com/iAmKankan/Mathematics/blob/main/LinearAlgebra/README.md)
#### [The Definition](https://github.com/iAmKankan/Mathematics/blob/main/LinearAlgebra/README.md#what-is-linear-algebra)
* [Scalar](#scaler)
* [Vector](#vector)
    * [Difference between Scalar and Vector quantities](#difference-between-scalar-and-vector-quantities)
* [Matrix](#matrix)
   * [Difference between Vector and Matrix](#difference-between-vector-and-matrix)
* [Tensors](#tensors)
   * [Tensors Orders](#tensors-orders)
#### [Basic Operations on Linear algebra](#basic-operations)
* [Addition, Broadcasting(a special type of addition)](#addition-and-broadcasting-of-matrix)
   *  [Normal Addition](#%EF%B8%8F-normal-addition-)
   *  [Broadcasting](#%EF%B8%8F-broadcasting-)
* [Multiplication](#multiplication-of-matrix)
   * [Matrix product](#%EF%B8%8F-matrix-product-) 
   * [Dot product](#%EF%B8%8F-dot-product---vector-notation-or--matrix-notation) 
   * [Hadamard Product(Elimentwise Multiplication)](#%EF%B8%8F-hadamard-product-elimentwise-multiplication-) 
* [Matrix Transpose](#matrix-transpose-)
* [Matrix Inverse](#matrix-inverse--)
#### [Cosine Similarity](#cosine-similarity)
---
* [Eigendecompositions](https://github.com/iAmKankan/Mathematics/blob/main/eigendecompositions.md)
* [Series]()
   * [Maclaurin](https://github.com/iAmKankan/Mathematics/blob/main/formula.md#maclaurin-series)

* [Calculus](#what-is-calculus)
   * [Differential calculus](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Derivatives and Differentiation](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Partial Derivatives](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Gradients](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Chain Rule](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Power Rule](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Other Formulas](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Maxima Minima](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
     * [Gradient](https://github.com/iAmKankan/Mathematics/blob/main/D_calculus.md)
   * [Newton-Raphson Method]

* Probability
* [Statistics](https://github.com/iAmKankan/Statistics)

* [Trigonometry](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
   * [Trigonometric functions](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
     * [Sin Theta](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
     * [Cos or Cosin Theta](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
     * [Tan Theta](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
     * [Cosec Theta](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
     * [Sec Theta](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
     * [Cot Theta](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
  * [Pythagorus Theorem](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
  * [Eucledian Distance](https://github.com/iAmKankan/Mathematics/blob/main/trigonometry.md)
  
* [Logarithm](https://github.com/iAmKankan/Mathematics/blob/main/logarithm.md)
  
* [Norm](https://github.com/iAmKankan/Mathematics/tree/main/analytic-geometry#norms)

### [_Symbols_](https://github.com/iAmKankan/Mathematics/blob/main/symbols.md)

## [References](#references)

![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)

## Math Symbols cheat sheet
<img src="https://user-images.githubusercontent.com/12748752/183649932-b355ad33-b234-4ea2-a78e-76454fc8e2a2.png" aligh="top" width=50%/> <img src="https://user-images.githubusercontent.com/12748752/183649921-58ab92ee-a5ab-4169-9f53-d5f92c9f75fd.png" aligh="top" width=50%/> 

### Multivariate Calculus
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)

* Helps in solving problems of optimizing the Machine Learning model
* Real World problems use calculus for many operations

### Multivariable Calculus Topics
![dark](https://user-images.githubusercontent.com/12748752/132402918-976c6cc7-cc94-4267-9513-b3937504eb63.png)



  ### [Differential Calculus](https://github.com/iAmKankan/Mathematics/blob/main/differentialc.md#differential-calculus)
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)
- Partial Derivatives
- Differentiation
- Derivatives
- Chain Rule
- Directional Derivative and the Gradient
- Applications of Differential Calculus
 ### Integral calculus	
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)
* Double integrals
- Triple Integrals
- Changing Variables
 ### Curves and surfaces	
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)
- Parametrized Curve
- Length of the Curve
- Parameterized Surfaces
- Surface Area of Parameterized Surfaces
 ### [Vector Field](https://github.com/iAmKankan/Mathematics/blob/main/vector.md)
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)
- Vector Field Basics
- Vector Operators

### Maxima Minima
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)

### Gradient
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)
* Represented by Del operator and Greek Nabla symbol
> <img src="https://latex.codecogs.com/svg.image?\nabla\&space;&space;=&space;\&space;\mathrm{Nabla\&space;Symbol;\&space;Del\&space;Operator&space;}" title="\nabla\ = \ \mathrm{Nabla\ Symbol;\ Del\ Operator }" />

<img src="https://latex.codecogs.com/svg.image?\nabla&space;f(x,y)=\&space;\frac{\partial&space;f}{\partial&space;x}\&space;\widehat{i}\&space;&plus;&space;\&space;\frac{\partial&space;f}{\partial&space;y}\&space;\widehat{j}\&space;=\&space;\begin{bmatrix}&space;\frac{\partial&space;f}{\partial&space;x}&space;\\&space;\\&space;\frac{\partial&space;f}{\partial&space;y}&space;\\\end{bmatrix}&space;" title="\nabla f(x,y)=\ \frac{\partial f}{\partial x}\ \widehat{i}\ + \ \frac{\partial f}{\partial y}\ \widehat{j}\ =\ \begin{bmatrix} \frac{\partial f}{\partial x} \\ \\ \frac{\partial f}{\partial y} \\\end{bmatrix} " />

### Integration over curves and Surfaces
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)
- Line Integral
- Surface Integral
 ### Fundamental Theorem of Vector Calculus
![light](https://user-images.githubusercontent.com/12748752/132402912-1a2a215e-de2f-4536-b28e-e75197136af9.png)
- Gradient Theorem for Line Integrals
- Green’s Theorem
- Stokes’ Theorem
- Divergence Theorem

## References
![dark](https://user-images.githubusercontent.com/12748752/132402918-976c6cc7-cc94-4267-9513-b3937504eb63.png)
* [YouTube Videos](https://www.youtube.com/watch?v=1VSZtNYMntM)
* [Dive into Deep Learning](https://d2l.ai/index.html)
